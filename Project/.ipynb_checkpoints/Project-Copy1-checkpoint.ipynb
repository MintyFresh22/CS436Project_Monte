{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "green-surgeon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk import word_tokenize\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continent-gender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192427\n",
      "98171\n",
      "141576\n",
      "55563\n",
      "18963\n",
      "34110\n",
      "96996\n",
      "86063\n",
      "69213\n",
      "210663\n",
      "260819\n",
      "96825\n",
      "25833\n",
      "37360\n",
      "23140\n"
     ]
    }
   ],
   "source": [
    "fileids = []\n",
    "for fileid in nltk.corpus.gutenberg.fileids():\n",
    "    #Include the appropriate texts from the corpus \n",
    "    #Don't include the bible or poems\n",
    "    if fileid != 'bible-kjv.txt' and fileid != 'blake-poems.txt' and fileid != 'whitman-leaves.txt':\n",
    "        fileids.append(fileid)\n",
    "        \n",
    "for fileid in fileids:\n",
    "    print(len(gutenberg.words(fileid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dirty-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    " stories_file = open(\"stories.csv\",\"r\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "refined-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded story 0...\n",
      "Loaded story 1...\n",
      "Loaded story 2...\n",
      "Loaded story 3...\n",
      "Loaded story 4...\n",
      "Loaded story 5...\n",
      "Loaded story 6...\n",
      "Loaded story 7...\n",
      "Loaded story 8...\n",
      "Loaded story 9...\n",
      "Loaded story 10...\n",
      "Loaded story 11...\n",
      "Loaded story 12...\n",
      "Loaded story 13...\n",
      "Loaded story 14...\n",
      "Loaded story 15...\n",
      "Loaded story 16...\n",
      "Loaded story 17...\n",
      "Loaded story 18...\n",
      "Loaded story 19...\n",
      "Loaded story 20...\n",
      "Loaded story 21...\n",
      "Loaded story 22...\n",
      "Loaded story 23...\n",
      "Loaded story 24...\n",
      "Loaded story 25...\n",
      "Loaded story 26...\n",
      "Loaded story 27...\n",
      "Loaded story 28...\n",
      "Loaded story 29...\n",
      "Loaded story 30...\n",
      "Loaded story 31...\n",
      "Loaded story 32...\n",
      "Loaded story 33...\n",
      "Loaded story 34...\n",
      "Loaded story 35...\n",
      "Loaded story 36...\n",
      "Loaded story 37...\n",
      "Loaded story 38...\n",
      "Loaded story 39...\n",
      "Loaded story 40...\n",
      "Loaded story 41...\n",
      "Loaded story 42...\n",
      "Loaded story 43...\n",
      "Loaded story 44...\n",
      "Loaded story 45...\n",
      "Loaded story 46...\n",
      "Loaded story 47...\n",
      "Loaded story 48...\n",
      "Loaded story 49...\n"
     ]
    }
   ],
   "source": [
    "training_story_count = 50\n",
    "# training_stories = [\"\" * i for i in range(0,training_story_count+1)]\n",
    "training_stories = [[\"\"] * i for i in range(0,training_story_count+1)]\n",
    "\n",
    "curr_story = \"\"\n",
    "prev_story = \"\"\n",
    "story_num = -1\n",
    "\n",
    "stories = stories_file.readlines()\n",
    "for line in stories:\n",
    "    if story_num < training_story_count:\n",
    "        if line.find(\"START OF THIS PROJECT GUTENBERG EBOOK\") != -1:\n",
    "            if story_num+1 != 0:\n",
    "                print(\"Loaded story \" + str(story_num) + \"...\")\n",
    "            story_num = story_num + 1\n",
    "        elif line != \"\\n\":\n",
    "            #             training_stories[story_num] += line\n",
    "            \n",
    "            training_stories[story_num].append(line)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "training_stories.pop()\n",
    "stories_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "growing-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_batch_size = 8\n",
    "\n",
    "curr_batch_size = 0\n",
    "for i,story in enumerate(training_stories):\n",
    "    batched_story = [\"\"]\n",
    "    batch_num = 0\n",
    "    for line in story:\n",
    "        if curr_batch_size < line_batch_size:\n",
    "            batched_story[batch_num] += line\n",
    "            curr_batch_size += 1\n",
    "        else:\n",
    "            batched_story.append(line)\n",
    "            batch_num += 1\n",
    "            curr_batch_size = 0\n",
    "    training_stories[i] = batched_story\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interested-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle_training_stories = open(\"training_stories.pickle\",\"wb\")\n",
    "# pickle.dump(training_stories,pickle_training_stories)\n",
    "# pickle_training_stories.close()\n",
    "\n",
    "training_stories = pickle.load(open(\"training_stories.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "respected-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 0 num batches: 55\n",
      "Story 1 num batches: 75\n",
      "Story 2 num batches: 468\n",
      "Story 3 num batches: 61\n",
      "Story 4 num batches: 962\n",
      "Story 5 num batches: 75\n",
      "Story 6 num batches: 83\n",
      "Story 7 num batches: 71\n",
      "Story 8 num batches: 21\n",
      "Story 9 num batches: 54\n",
      "Story 10 num batches: 793\n",
      "Story 11 num batches: 60\n",
      "Story 12 num batches: 17\n",
      "Story 13 num batches: 74\n",
      "Story 14 num batches: 17213\n",
      "Story 15 num batches: 31\n",
      "Story 16 num batches: 809\n",
      "Story 17 num batches: 26\n",
      "Story 18 num batches: 454\n",
      "Story 19 num batches: 258\n",
      "Story 20 num batches: 1124\n",
      "Story 21 num batches: 66\n",
      "Story 22 num batches: 519\n",
      "Story 23 num batches: 510\n",
      "Story 24 num batches: 63\n",
      "Story 25 num batches: 108\n",
      "Story 26 num batches: 391\n",
      "Story 27 num batches: 583\n",
      "Story 28 num batches: 78\n",
      "Story 29 num batches: 2252\n",
      "Story 30 num batches: 19\n",
      "Story 31 num batches: 68\n",
      "Story 32 num batches: 59\n",
      "Story 33 num batches: 1828\n",
      "Story 34 num batches: 41\n",
      "Story 35 num batches: 213\n",
      "Story 36 num batches: 958\n",
      "Story 37 num batches: 45\n",
      "Story 38 num batches: 68\n",
      "Story 39 num batches: 51\n",
      "Story 40 num batches: 86\n",
      "Story 41 num batches: 629\n",
      "Story 42 num batches: 56\n",
      "Story 43 num batches: 626\n",
      "Story 44 num batches: 732\n",
      "Story 45 num batches: 189\n",
      "Story 46 num batches: 27\n",
      "Story 47 num batches: 269\n",
      "Story 48 num batches: 71\n",
      "Story 49 num batches: 718\n"
     ]
    }
   ],
   "source": [
    "for i,batched_story in enumerate(training_stories):\n",
    "    print(\"Story \" + str(i) + \" num batches: \" + str(len(batched_story)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "disciplinary-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences = []\n",
    "training_words = []\n",
    "for batched_story in training_stories[:1]:\n",
    "    for batch in batched_story:\n",
    "        for sent in nltk.sent_tokenize(batch.lower()):\n",
    "            training_sentences.append(sent)\n",
    "            for word in nltk.word_tokenize(sent):\n",
    "                training_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "# word2vec_model = Word2Vec(training_words,)\n",
    "# TODO laod a pretrained word2vec model\n",
    "# convert text into word2vec embeddings\n",
    "# make and train a neural network to classify a single sentence as either\n",
    "# cohesive or not cohesive \n",
    "# use that cohesive classifier to determine how cohesive my finetuned GPT2 is\n",
    "# consider doing this with coherence across multiple sentences with convnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "confused-accent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class StoryDataset(Dataset):\n",
    "    def __init__(self,text):\n",
    "        self.text = text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.text[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "class StoryGenerator:\n",
    "    def __init__(self,tokenizer=None,model=None,optimizer=None,loss=None,alt_sent_gen_enabled=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        if tokenizer == None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            \n",
    "        self.model = model\n",
    "        if model == None:\n",
    "            self.model = GPT2LMHeadModel.from_pretrained('gpt2',pad_token_id=self.tokenizer.eos_token_id)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        if optimizer == None:\n",
    "            self.optimizer = AdamW(self.model.parameters(),lr=1e-5)\n",
    "            \n",
    "        self.loss = loss\n",
    "        if loss == None:\n",
    "            self.loss = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.alt_sent_gen_enabled = alt_sent_gen_enabled\n",
    "        \n",
    "    def generate_sentences(self,sent,sent_end_symbols=\".?!\",max_len=64,num_sentences=1):\n",
    "        for i in range(0,num_sentences):\n",
    "            sent += self.generate_sentence(sent=sent,sent_end_symbols=sent_end_symbols,max_len=max_len)\n",
    "        return sent\n",
    "        \n",
    "    def generate_sentence(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        if self.alt_sent_gen_enabled:\n",
    "            return self.alt_sent_gen(sent=sent)\n",
    "        return self.sent_gen(sent=sent)\n",
    "    \n",
    "    def sent_gen(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        end_symbols = re.compile('['+ sent_end_symbols + ']')\n",
    "        \n",
    "        sent_len = 0\n",
    "        decoded_output = sent\n",
    "        end_symbol = None\n",
    "        start_pos = len(decoded_output)\n",
    "        while end_symbol is None or (sent_len < max_len and end_symbols.match(end_symbol) is None):\n",
    "            input_ids = self.tokenizer.encode(decoded_output, return_tensors=\"pt\")\n",
    "            output_length = input_ids.size()[1]+1\n",
    "            output = self.model.generate(input_ids, min_length=output_length,max_length=output_length, num_beams=3, do_sample=True, repetition_penalty=4.0)\n",
    "            decoded_output = self.tokenizer.decode(output[0])\n",
    "            end_symbol = decoded_output[len(decoded_output)-1]\n",
    "            #right now just add 1 for every token added\n",
    "            sent_len = sent_len + 1 \n",
    "        return decoded_output[start_pos:]\n",
    "    \n",
    "    def alt_sent_gen(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        end_of_sent = len(sent)-1\n",
    "        \n",
    "        decoded_output = sent\n",
    "        input_ids = self.tokenizer.encode(decoded_output, return_tensors=\"pt\")\n",
    "        output = self.model.generate(input_ids, max_length=max_len, num_beams=3, do_sample=True, early_stopping=True, repetition_penalty=4.0)\n",
    "        decoded_output = self.tokenizer.decode(output[0])\n",
    "#         print(\"full generation: \")\n",
    "#         print(decoded_output)\n",
    "        \n",
    "        all_new_additions = decoded_output[end_of_sent+1:]\n",
    "        symbol_first_index = -1\n",
    "        for symbol in sent_end_symbols:\n",
    "            try:\n",
    "                new_symbol_first_index = all_new_additions.index(symbol)\n",
    "                if symbol_first_index == -1 or new_symbol_first_index < symbol_first_index:\n",
    "                    symbol_first_index = new_symbol_first_index\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if symbol_first_index < 0:\n",
    "            self.alt_sent_gen(sent=sent)\n",
    "#             raise Exception(\"No Punctuation Detected\")\n",
    "#         print(\"all_new_additions: \")\n",
    "#         print(all_new_additions)\n",
    "        new_sentence = all_new_additions[:symbol_first_index+1]\n",
    "        return new_sentence\n",
    "    \n",
    "    def fine_tune(self,story_loader):\n",
    "        for story_batch in tqdm(story_loader):\n",
    "#             print(story_batch)\n",
    "#             print(\"tokenize\")\n",
    "            inputs = self.tokenizer(story_batch,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "#             print(\"output\")\n",
    "            outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "#             print(\"loss\")\n",
    "            loss = outputs.loss\n",
    "            print(loss)\n",
    "#             print(\"backward\")\n",
    "            loss.backward()\n",
    "#             print(\"optimizer\")\n",
    "            self.optimizer.step()\n",
    "#             print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "sitting-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token = tokenizer.eos_token,padding_side=\"right\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latin-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "# story_generator = StoryGenerator(tokenizer=tokenizer,model=model)\n",
    "story_generator = pickle.load(open(\"trained_generator.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "handy-moisture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7920, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|████████████                                                                        | 1/7 [00:10<01:05, 11.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3993, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|████████████████████████                                                            | 2/7 [00:21<00:53, 10.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8272, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████████████████████████████████████                                                | 3/7 [00:29<00:40, 10.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2560, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [00:38<00:29,  9.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5446, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:47<00:19,  9.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4015, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:57<00:09,  9.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2569, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [01:06<00:00,  9.50s/it]\u001b[A\n",
      " 25%|█████████████████████                                                               | 1/4 [01:07<03:23, 67.80s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7931, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▎                                                                          | 1/10 [00:15<02:21, 15.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8994, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:24<01:49, 13.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2245, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:33<01:24, 12.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4700, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:43<01:08, 11.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7160, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:52<00:54, 10.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9412, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:01<00:41, 10.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4920, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:11<00:30, 10.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3947, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:20<00:19,  9.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6232, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:29<00:09,  9.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2836, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:33<00:00,  9.39s/it]\u001b[A\n",
      " 50%|██████████████████████████████████████████                                          | 2/4 [02:43<02:32, 76.04s/it]\n",
      "  0%|                                                                                           | 0/59 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2908, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|█▍                                                                                 | 1/59 [00:13<13:30, 13.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1407, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▊                                                                                | 2/59 [00:23<12:08, 12.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2159, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|████▏                                                                              | 3/59 [00:33<11:06, 11.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8997, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▋                                                                             | 4/59 [00:43<10:21, 11.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7739, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|███████                                                                            | 5/59 [00:53<09:42, 10.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5976, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▍                                                                          | 6/59 [01:03<09:25, 10.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9392, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█████████▊                                                                         | 7/59 [01:12<08:51, 10.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9340, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|███████████▎                                                                       | 8/59 [01:23<08:40, 10.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6835, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|████████████▋                                                                      | 9/59 [01:32<08:23, 10.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9654, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▉                                                                    | 10/59 [01:42<08:01,  9.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9862, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|███████████████▎                                                                  | 11/59 [01:51<07:43,  9.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1799, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▋                                                                 | 12/59 [02:00<07:24,  9.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9507, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██████████████████                                                                | 13/59 [02:09<07:16,  9.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6711, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|███████████████████▍                                                              | 14/59 [02:19<07:11,  9.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5657, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|████████████████████▊                                                             | 15/59 [02:29<07:10,  9.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0466, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██████████████████████▏                                                           | 16/59 [02:39<06:59,  9.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8016, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|███████████████████████▋                                                          | 17/59 [02:49<06:47,  9.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9229, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|█████████████████████████                                                         | 18/59 [02:59<06:48,  9.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4866, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|██████████████████████████▍                                                       | 19/59 [03:11<06:54, 10.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1185, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███████████████████████████▊                                                      | 20/59 [03:21<06:45, 10.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9938, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|█████████████████████████████▏                                                    | 21/59 [03:32<06:36, 10.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2406, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|██████████████████████████████▌                                                   | 22/59 [03:41<06:19, 10.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0340, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███████████████████████████████▉                                                  | 23/59 [03:53<06:18, 10.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7846, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|█████████████████████████████████▎                                                | 24/59 [04:02<05:59, 10.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8261, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|██████████████████████████████████▋                                               | 25/59 [04:12<05:48, 10.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6199, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████████████████████████████████████▏                                             | 26/59 [04:22<05:30, 10.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4278, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|█████████████████████████████████████▌                                            | 27/59 [04:31<05:15,  9.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2609, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|██████████████████████████████████████▉                                           | 28/59 [04:42<05:08,  9.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7544, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████████████████████████████████████████▎                                         | 29/59 [04:52<05:00, 10.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6199, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████████████████████████████████████████▋                                        | 30/59 [05:02<04:55, 10.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5747, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|███████████████████████████████████████████                                       | 31/59 [05:13<04:53, 10.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8860, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|████████████████████████████████████████████▍                                     | 32/59 [05:23<04:35, 10.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5483, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████████████████████████████████████████████▊                                    | 33/59 [05:33<04:24, 10.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8460, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|███████████████████████████████████████████████▎                                  | 34/59 [05:42<04:03,  9.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7753, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|████████████████████████████████████████████████▋                                 | 35/59 [05:51<03:52,  9.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5986, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████████████████████████████████████████████████                                | 36/59 [06:01<03:44,  9.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7915, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|███████████████████████████████████████████████████▍                              | 37/59 [06:10<03:30,  9.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5625, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|████████████████████████████████████████████████████▊                             | 38/59 [06:21<03:25,  9.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4404, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████████████████████████████████████████████████████▏                           | 39/59 [06:31<03:15,  9.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6750, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|███████████████████████████████████████████████████████▌                          | 40/59 [06:40<03:04,  9.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2866, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|████████████████████████████████████████████████████████▉                         | 41/59 [06:51<03:02, 10.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9133, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|██████████████████████████████████████████████████████████▎                       | 42/59 [07:02<02:55, 10.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7949, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████████████████████████████████████████████████████████▊                      | 43/59 [07:12<02:43, 10.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4124, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|█████████████████████████████████████████████████████████████▏                    | 44/59 [07:22<02:32, 10.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8660, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|██████████████████████████████████████████████████████████████▌                   | 45/59 [07:32<02:22, 10.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7594, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▉                  | 46/59 [07:43<02:14, 10.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1230, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▎                | 47/59 [07:52<01:58,  9.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5219, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 48/59 [08:01<01:47,  9.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6101, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████████████████████████████████████████████████████████████████              | 49/59 [08:10<01:34,  9.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8302, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 50/59 [08:19<01:23,  9.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9048, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████████▉           | 51/59 [08:28<01:14,  9.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3401, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 52/59 [08:37<01:04,  9.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2072, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▋        | 53/59 [08:46<00:55,  9.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9067, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████       | 54/59 [08:56<00:46,  9.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6289, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▍     | 55/59 [09:06<00:38,  9.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3681, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▊    | 56/59 [09:17<00:29, 10.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0562, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 57/59 [09:26<00:19,  9.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4164, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████▌ | 58/59 [09:37<00:09,  9.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6745, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [09:41<00:00,  9.86s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [12:26<03:48, 228.24s/it]\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1967, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|██████████▌                                                                         | 1/8 [00:14<01:44, 14.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1092, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|█████████████████████                                                               | 2/8 [00:25<01:22, 13.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8735, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███████████████████████████████▌                                                    | 3/8 [00:35<01:02, 12.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8493, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 4/8 [00:45<00:46, 11.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1245, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|████████████████████████████████████████████████████▌                               | 5/8 [00:54<00:32, 10.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8896, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 6/8 [01:02<00:20, 10.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2939, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|█████████████████████████████████████████████████████████████████████████▌          | 7/8 [01:10<00:09,  9.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7178, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [01:15<00:00,  9.46s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [13:43<00:00, 205.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for story in tqdm(training_stories[:4]):\n",
    "    story_dataset = StoryDataset(text=story)\n",
    "    story_loader = DataLoader(story_dataset, batch_size=8)\n",
    "    story_generator.fine_tune(story_loader=story_loader)\n",
    "    pickle_trained_model = open(\"trained_model.pickle\",\"wb\")\n",
    "    pickle.dump(story_generator.model,pickle_trained_model)\n",
    "    pickle_trained_model.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dutch-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_trained_generator = open(\"trained_generator.pickle\",\"wb\")\n",
    "pickle.dump(story_generator,pickle_trained_generator)\n",
    "pickle_trained_generator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "systematic-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first few sentences of your story as a prompt: Richard Aberton was a doctor living in London. He hadn't worked in seven years.\n",
      "Enter the length of your story (number of sentences): 10\n",
      "Richard Aberton was a doctor living in London. He hadn't worked in seven years.\n",
      "\n",
      "\n",
      "He had never met the man, and he didn't know what to do with him; but his wife's eyes were fixed on her husband as if she knew that it was not possible for him to be married again without some kind of legal obligation. She smiled at him:\n",
      "I'm sorry, sir, I suppose you don't want me to marry?\n",
      "Yes, sir, I suppose so. And yet there is no such thing as an obligation--a duty which does not exist under any other circumstances than one created by God. The fact that this woman did not wish to marry anyone else made her mind clear enough to Mr. Sallust.\n",
      "It seems to me that Mrs. Aberton has been obliged to give up her own marriage vows after they had been signed. But when we read about them, however, our minds became confused. It seemed to us that their wives might have wished to keep away from men who had committed adultery or whose husbands had done anything wrong.\n"
     ]
    }
   ],
   "source": [
    "user_sent = input(\"Enter the first few sentences of your story as a prompt: \")\n",
    "user_story_len = input(\"Enter the length of your story (number of sentences): \")\n",
    "story_generator.alt_sent_gen_enabled = False\n",
    "story = story_generator.generate_sentences(sent=user_sent,num_sentences=int(user_story_len))\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "killing-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_embedding(sent,story_generator=None):\n",
    "    #returns a list of word embeddings\n",
    "    if len(sent) == 0 or story_generator is None:\n",
    "        return None\n",
    "    sent_embedding = []\n",
    "    words = get_tokenized_sent(sent,story_generator)\n",
    "    for word in words:\n",
    "        sent_embedding.append(get_word_embedding(word,story_generator))\n",
    "    return sent_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "valid-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sent(sent,story_generator=None):\n",
    "    #returns a list of tokens/words tokenized by gpt-2 tokenizer\n",
    "    if len(sent) == 0 or story_generator is None:\n",
    "        return None\n",
    "    tokenized_sent = []\n",
    "    encoded_sent = story_generator.tokenizer.encode(sent)\n",
    "    for encoded_word in encoded_sent:\n",
    "        tokenized_sent.append(story_generator.tokenizer.decode(encoded_word))\n",
    "    return tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bigger-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word,story_generator=None):\n",
    "    #returns the gpt-2 embedding for a word\n",
    "    if len(word) == 0 or story_generator is None:\n",
    "        return None\n",
    "    w_encoded = story_generator.tokenizer(word)['input_ids']\n",
    "    w_tensor = torch.LongTensor(w_encoded)\n",
    "    return story_generator.model.transformer.wte(w_tensor).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "meaning-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "collectible-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, None, 64)          49152     \n",
      "=================================================================\n",
      "Total params: 49,152\n",
      "Trainable params: 49,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = story_generator.model.transformer.wte.embedding_dim\n",
    "cohesion_model = Sequential()\n",
    "# cohesion_model.add(layers.Embedding(input_dim=embeddings_dim,output_dim=64))\n",
    "cohesion_model.add(layers.SimpleRNN(64))\n",
    "cohesion_model.add(layers.Dense(10))\n",
    "cohesion_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-florida",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python A6",
   "language": "python",
   "name": "a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
