{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk import word_tokenize\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192427\n",
      "98171\n",
      "141576\n",
      "55563\n",
      "18963\n",
      "34110\n",
      "96996\n",
      "86063\n",
      "69213\n",
      "210663\n",
      "260819\n",
      "96825\n",
      "25833\n",
      "37360\n",
      "23140\n"
     ]
    }
   ],
   "source": [
    "fileids = []\n",
    "for fileid in nltk.corpus.gutenberg.fileids():\n",
    "    #Include the appropriate texts from the corpus \n",
    "    #Don't include the bible or poems\n",
    "    if fileid != 'bible-kjv.txt' and fileid != 'blake-poems.txt' and fileid != 'whitman-leaves.txt':\n",
    "        fileids.append(fileid)\n",
    "        \n",
    "for fileid in fileids:\n",
    "    print(len(gutenberg.words(fileid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " stories_file = open(\"stories.csv\",\"r\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded story 0...\n",
      "Loaded story 1...\n",
      "Loaded story 2...\n",
      "Loaded story 3...\n",
      "Loaded story 4...\n",
      "Loaded story 5...\n",
      "Loaded story 6...\n",
      "Loaded story 7...\n",
      "Loaded story 8...\n",
      "Loaded story 9...\n",
      "Loaded story 10...\n",
      "Loaded story 11...\n",
      "Loaded story 12...\n",
      "Loaded story 13...\n",
      "Loaded story 14...\n",
      "Loaded story 15...\n",
      "Loaded story 16...\n",
      "Loaded story 17...\n",
      "Loaded story 18...\n",
      "Loaded story 19...\n",
      "Loaded story 20...\n",
      "Loaded story 21...\n",
      "Loaded story 22...\n",
      "Loaded story 23...\n",
      "Loaded story 24...\n",
      "Loaded story 25...\n",
      "Loaded story 26...\n",
      "Loaded story 27...\n",
      "Loaded story 28...\n",
      "Loaded story 29...\n",
      "Loaded story 30...\n",
      "Loaded story 31...\n",
      "Loaded story 32...\n",
      "Loaded story 33...\n",
      "Loaded story 34...\n",
      "Loaded story 35...\n",
      "Loaded story 36...\n",
      "Loaded story 37...\n",
      "Loaded story 38...\n",
      "Loaded story 39...\n",
      "Loaded story 40...\n",
      "Loaded story 41...\n",
      "Loaded story 42...\n",
      "Loaded story 43...\n",
      "Loaded story 44...\n",
      "Loaded story 45...\n",
      "Loaded story 46...\n",
      "Loaded story 47...\n",
      "Loaded story 48...\n",
      "Loaded story 49...\n"
     ]
    }
   ],
   "source": [
    "training_story_count = 50\n",
    "# training_stories = [\"\" * i for i in range(0,training_story_count+1)]\n",
    "training_stories = [[\"\"] * i for i in range(0,training_story_count+1)]\n",
    "\n",
    "curr_story = \"\"\n",
    "prev_story = \"\"\n",
    "story_num = -1\n",
    "\n",
    "stories = stories_file.readlines()\n",
    "for line in stories:\n",
    "    if story_num < training_story_count:\n",
    "        if line.find(\"START OF THIS PROJECT GUTENBERG EBOOK\") != -1:\n",
    "            if story_num+1 != 0:\n",
    "                print(\"Loaded story \" + str(story_num) + \"...\")\n",
    "            story_num = story_num + 1\n",
    "        else:\n",
    "#             training_stories[story_num] += line\n",
    "            training_stories[story_num].append(line)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "training_stories.pop()\n",
    "stories_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_training_stories = open(\"training_stories.pickle\",\"wb\")\n",
    "pickle.dump(training_stories,pickle_training_stories)\n",
    "pickle_training_stories.close()\n",
    "\n",
    "training_stories = pickle.load(open(\"training_stories.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class StoryDataset(Dataset):\n",
    "    def __init__(self,text):\n",
    "        self.text = text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.text[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "import re\n",
    "\n",
    "class StoryGenerator:\n",
    "    def __init__(self,tokenizer=None,model=None,optimizer=None,loss=None,alt_sent_gen_enabled=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        if tokenizer == None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            \n",
    "        self.model = model\n",
    "        if model == None:\n",
    "            self.model = GPT2LMHeadModel.from_pretrained('gpt2',pad_token_id=self.tokenizer.eos_token_id)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        if optimizer == None:\n",
    "            self.optimizer = AdamW(self.model.parameters(),lr=1e-5)\n",
    "            \n",
    "        self.loss = loss\n",
    "        if loss == None:\n",
    "            self.loss = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.alt_sent_gen_enabled = alt_sent_gen_enabled\n",
    "        \n",
    "    def generate_sentences(self,sent,sent_end_symbols=\".?!\",max_len=64,num_sentences=1):\n",
    "        for i in range(0,num_sentences):\n",
    "            sent += self.generate_sentence(sent=sent,sent_end_symbols=sent_end_symbols,max_len=max_len)\n",
    "        return sent\n",
    "        \n",
    "    def generate_sentence(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        if self.alt_sent_gen_enabled:\n",
    "            return self.alt_sent_gen(sent=sent)\n",
    "        return self.sent_gen(sent=sent)\n",
    "    \n",
    "    def sent_gen(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        end_symbols = re.compile('['+ sent_end_symbols + ']')\n",
    "        \n",
    "        sent_len = 0\n",
    "        decoded_output = sent\n",
    "        end_symbol = None\n",
    "        start_pos = len(decoded_output)\n",
    "        while end_symbol is None or (sent_len < max_len and end_symbols.match(end_symbol) is None):\n",
    "            input_ids = self.tokenizer.encode(decoded_output, return_tensors=\"pt\")\n",
    "            output_length = input_ids.size()[1]+1\n",
    "            output = self.model.generate(input_ids, min_length=output_length,max_length=output_length, num_beams=3, do_sample=True, repetition_penalty=4.0)\n",
    "            decoded_output = self.tokenizer.decode(output[0])\n",
    "            end_symbol = decoded_output[len(decoded_output)-1]\n",
    "            #right now just add 1 for every token added\n",
    "            sent_len = sent_len + 1 \n",
    "        return decoded_output[start_pos:]\n",
    "    \n",
    "    def alt_sent_gen(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        end_of_sent = len(sent)-1\n",
    "        \n",
    "        decoded_output = sent\n",
    "        input_ids = self.tokenizer.encode(decoded_output, return_tensors=\"pt\")\n",
    "        output = self.model.generate(input_ids, max_length=max_len, num_beams=3, do_sample=True, early_stopping=True, repetition_penalty=4.0)\n",
    "        decoded_output = self.tokenizer.decode(output[0])\n",
    "#         print(\"full generation: \")\n",
    "#         print(decoded_output)\n",
    "        \n",
    "        all_new_additions = decoded_output[end_of_sent+1:]\n",
    "        symbol_first_index = -1\n",
    "        for symbol in sent_end_symbols:\n",
    "            try:\n",
    "                new_symbol_first_index = all_new_additions.index(symbol)\n",
    "                if symbol_first_index == -1 or new_symbol_first_index < symbol_first_index:\n",
    "                    symbol_first_index = new_symbol_first_index\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if symbol_first_index < 0:\n",
    "            alt_sent_gen(sent=sent)\n",
    "#             raise Exception(\"No Punctuation Detected\")\n",
    "#         print(\"all_new_additions: \")\n",
    "#         print(all_new_additions)\n",
    "        new_sentence = all_new_additions[:symbol_first_index+1]\n",
    "        return new_sentence\n",
    "    \n",
    "    def fine_tune(self,story_loader):\n",
    "        for story_batch in story_loader:\n",
    "            inputs = self.tokenizer(story_batch,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "            outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token=\"<|endoftext|>\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_generator = StoryGenerator(tokenizer=tokenizer,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# for story in training_stories:\n",
    "#     story_generator.fine_tune(story[:1024])\n",
    "# story_generator.fine_tune(training_stories[0][:1024])\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for story in tqdm(training_stories):\n",
    "    story_dataset = StoryDataset(text=story)\n",
    "    story_loader = DataLoader(story_dataset, batch_size=64)\n",
    "    story_generator.fine_tune(story_loader=story_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Ricky Bobby, I'm from Louisiana and my best friends name is bob. Me and bob enjoy hunting mountain lions in the hills. We love to hunt but we don't always have a lot of time for it.\n",
      "My name is Ricky Bobby, I'm from Louisiana and my best friends name is bob. Me and bob enjoy hunting mountain lions in the hills. We love to hunt but we don't always have a lot of time for it.\n",
      "\n",
      "\n",
      "I am so excited to be back with you guys!\n",
      "My name is Ricky Bobby, I'm from Louisiana and my best friends name is bob. Me and bob enjoy hunting mountain lions in the hills. We love to hunt but we don't always have a lot of time for it.\n",
      "\n",
      "\n",
      "I am so excited to be back with you guys! It's been great being here since day one when all our animals were safe and happy.\n",
      "My name is Ricky Bobby, I'm from Louisiana and my best friends name is bob. Me and bob enjoy hunting mountain lions in the hills. We love to hunt but we don't always have a lot of time for it.\n",
      "\n",
      "\n",
      "I am so excited to be back with you guys! It's been great being here since day one when all our animals were safe and happy. Our dogs are loving their new home and now they're getting ready to get out there and play again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My name is Ricky Bobby, I'm from Louisiana and my best friends name is bob. Me and bob enjoy hunting mountain lions in the hills. We love to hunt but we don't always have a lot of time for it.\\n\\n\\nI am so excited to be back with you guys! It's been great being here since day one when all our animals were safe and happy. Our dogs are loving their new home and now they're getting ready to get out there and play again.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysent = \"My name is Ricky Bobby, I'm from Louisiana and my best friends name is bob. Me and bob enjoy hunting mountain lions in the hills.\"\n",
    "story_generator.generate_sentences(sent=mysent,num_sentences=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python A6",
   "language": "python",
   "name": "a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
