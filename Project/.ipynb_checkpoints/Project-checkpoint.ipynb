{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contrary-picture",
   "metadata": {},
   "source": [
    "# Run all cells in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confused-accent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reflected-secretary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class StoryDataset(Dataset):\n",
    "    def __init__(self,text):\n",
    "        self.text = text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.text[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "editorial-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "class StoryGenerator:\n",
    "    def __init__(self,tokenizer=None,model=None,optimizer=None,loss=None,alt_sent_gen_enabled=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        if tokenizer == None:\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "            \n",
    "        self.model = model\n",
    "        if model == None:\n",
    "            self.model = GPT2LMHeadModel.from_pretrained('gpt2',pad_token_id=self.tokenizer.eos_token_id)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        if optimizer == None:\n",
    "            self.optimizer = AdamW(self.model.parameters(),lr=1e-5)\n",
    "            \n",
    "        self.loss = loss\n",
    "        if loss == None:\n",
    "            self.loss = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.alt_sent_gen_enabled = alt_sent_gen_enabled\n",
    "        \n",
    "    def generate_sentences(self,sent,sent_end_symbols=\".?!\",max_len=64,num_sentences=1):\n",
    "        for i in range(0,num_sentences):\n",
    "            sent += self.generate_sentence(sent=sent,sent_end_symbols=sent_end_symbols,max_len=max_len)\n",
    "        return sent\n",
    "        \n",
    "    def generate_sentence(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        if self.alt_sent_gen_enabled:\n",
    "            return self.alt_sent_gen(sent=sent)\n",
    "        return self.sent_gen(sent=sent)\n",
    "    \n",
    "    def sent_gen(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        end_symbols = re.compile('['+ sent_end_symbols + ']')\n",
    "        \n",
    "        sent_len = 0\n",
    "        decoded_output = sent\n",
    "        end_symbol = None\n",
    "        start_pos = len(decoded_output)\n",
    "        while end_symbol is None or (sent_len < max_len and end_symbols.match(end_symbol) is None):\n",
    "            input_ids = self.tokenizer.encode(decoded_output, return_tensors=\"pt\")\n",
    "            output_length = input_ids.size()[1]+1\n",
    "            output = self.model.generate(input_ids, min_length=output_length,max_length=output_length, num_beams=3, do_sample=True, repetition_penalty=4.0)\n",
    "            decoded_output = self.tokenizer.decode(output[0])\n",
    "            end_symbol = decoded_output[len(decoded_output)-1]\n",
    "            #right now just add 1 for every token added\n",
    "            sent_len = sent_len + 1 \n",
    "        return decoded_output[start_pos:]\n",
    "    \n",
    "    def alt_sent_gen(self,sent,sent_end_symbols=\".?!\",max_len=64):\n",
    "        end_of_sent = len(sent)-1\n",
    "        \n",
    "        decoded_output = sent\n",
    "        input_ids = self.tokenizer.encode(decoded_output, return_tensors=\"pt\")\n",
    "        output = self.model.generate(input_ids, max_length=max_len, num_beams=3, do_sample=True, early_stopping=True, repetition_penalty=4.0)\n",
    "        decoded_output = self.tokenizer.decode(output[0])\n",
    "        \n",
    "        all_new_additions = decoded_output[end_of_sent+1:]\n",
    "        symbol_first_index = -1\n",
    "        for symbol in sent_end_symbols:\n",
    "            try:\n",
    "                new_symbol_first_index = all_new_additions.index(symbol)\n",
    "                if symbol_first_index == -1 or new_symbol_first_index < symbol_first_index:\n",
    "                    symbol_first_index = new_symbol_first_index\n",
    "            except ValueError:\n",
    "                pass\n",
    "        if symbol_first_index < 0:\n",
    "            self.alt_sent_gen(sent=sent)\n",
    "        new_sentence = all_new_additions[:symbol_first_index+1]\n",
    "        return new_sentence\n",
    "    \n",
    "    def fine_tune(self,story_loader):\n",
    "        for story_batch in tqdm(story_loader):\n",
    "            inputs = self.tokenizer(story_batch,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "            outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            print(loss)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "killing-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_embedding(sent,story_generator=None):\n",
    "    #returns a list of word embeddings\n",
    "    if story_generator is None: \n",
    "        return None\n",
    "    if len(sent) == 0:\n",
    "        return \"\"\n",
    "    sent_embedding = []\n",
    "    words = get_tokenized_sent(sent,story_generator)\n",
    "    for word in words:\n",
    "#         sent_embedding.append(get_word_embedding(word,story_generator))\n",
    "        sent_embedding += get_word_embedding(word,story_generator)\n",
    "    return sent_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "valid-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_sent(sent,story_generator=None):\n",
    "    #returns a list of tokens/words tokenized by gpt-2 tokenizer\n",
    "    if story_generator is None: \n",
    "        return None\n",
    "    if len(sent) == 0:\n",
    "        return \"\"\n",
    "    tokenized_sent = []\n",
    "#     tokenized_sent = tf.Tensor([],dtype=tf.int64)\n",
    "    encoded_sent = story_generator.tokenizer.encode(sent)\n",
    "    for encoded_word in encoded_sent:\n",
    "        tokenized_sent.append(story_generator.tokenizer.decode(encoded_word))\n",
    "    return tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bigger-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_word_embedding(word,story_generator=None):\n",
    "    #returns the gpt-2 embedding for a word\n",
    "    if len(word) == 0 or story_generator is None:\n",
    "        return None\n",
    "    w_encoded = story_generator.tokenizer(word)['input_ids']\n",
    "    w_tensor = torch.LongTensor(w_encoded)\n",
    "    return story_generator.model.transformer.wte(w_tensor).data.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-observer",
   "metadata": {},
   "source": [
    "# Don't run cells in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "sitting-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token = tokenizer.eos_token,padding_side=\"right\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token = \"<|endoftext|>\",padding_side=\"right\")\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "usual-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "latin-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_generator = StoryGenerator(tokenizer=tokenizer,model=model)\n",
    "# story_generator = pickle.load(open(\"trained_generator.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dirty-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    " stories_file = open(\"stories.csv\",\"r\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "refined-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded story 0...\n",
      "Loaded story 1...\n",
      "Loaded story 2...\n",
      "Loaded story 3...\n"
     ]
    }
   ],
   "source": [
    "training_story_count = 4\n",
    "training_stories = [[\"\"] * i for i in range(0,training_story_count+1)]\n",
    "\n",
    "curr_story = \"\"\n",
    "prev_story = \"\"\n",
    "story_num = -1\n",
    "\n",
    "stories = stories_file.readlines()\n",
    "for line in stories:\n",
    "    if story_num < training_story_count:\n",
    "        if line.find(\"START OF THIS PROJECT GUTENBERG EBOOK\") != -1:\n",
    "            if story_num+1 != 0:\n",
    "                print(\"Loaded story \" + str(story_num) + \"...\")\n",
    "            story_num = story_num + 1\n",
    "        elif line != \"\\n\":            \n",
    "            training_stories[story_num].append(line.strip())\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "training_stories.pop()\n",
    "stories_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charged-hamburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.28947368421053\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "mean_line_len = statistics.mean([len(line) for line in training_stories[0]])\n",
    "print(mean_line_len)\n",
    "cohesion_training_stories = copy.deepcopy(training_stories)\n",
    "cohesion_text_len = int(2 * mean_line_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accessible-brick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cohesion_training_text = []\n",
    "cohesion_training_labels = []\n",
    "for story in cohesion_training_stories[:training_story_count]:\n",
    "    cohesion_training_sents = []\n",
    "    curr_len = 0\n",
    "    for sent in story:\n",
    "        if curr_len >= cohesion_text_len:\n",
    "            cohesion_training_text.append(cohesion_training_sents)\n",
    "            cohesion_training_labels.append(1)\n",
    "            cohesion_training_sents = []\n",
    "            curr_len = 0\n",
    "        sent_tokenized = get_sent_embedding(sent,story_generator)\n",
    "        if len(sent_tokenized) + curr_len <= cohesion_text_len:\n",
    "            cohesion_training_sents += sent_tokenized\n",
    "            curr_len += len(sent_tokenized) \n",
    "        else:\n",
    "            for word in sent_tokenized:\n",
    "                if curr_len + 1 <= cohesion_text_len:\n",
    "                    cohesion_training_sents.append(word)\n",
    "                    curr_len += 1\n",
    "                else:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surrounded-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_cohesion_training_text = open(\"cohesion_training_text.pickle\",\"wb\")\n",
    "pickle.dump(cohesion_training_text,pickle_cohesion_training_text)\n",
    "pickle_cohesion_training_text.close()\n",
    "\n",
    "# cohesion_training_stories = pickle.load(open(\"cohesion_training_text.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "charming-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "neg_cohesion_train_txt = []\n",
    "neg_cohesion_train_labels = []\n",
    "for story in cohesion_training_stories[:training_story_count]:\n",
    "    neg_cohesion_train_sents = []\n",
    "    curr_len = 0\n",
    "    for sent in story:\n",
    "        if curr_len >= cohesion_text_len:\n",
    "            neg_cohesion_train_txt.append(neg_cohesion_train_sents)\n",
    "            neg_cohesion_train_labels.append(0)\n",
    "            neg_cohesion_train_sents = []\n",
    "            curr_len = 0\n",
    "        sent_tokenized = get_sent_embedding(sent,story_generator)\n",
    "        shuffle(sent_tokenized)\n",
    "        if len(sent_tokenized) + curr_len <= cohesion_text_len:\n",
    "            neg_cohesion_train_sents += sent_tokenized\n",
    "            curr_len += len(sent_tokenized) \n",
    "        else:\n",
    "            for word in sent_tokenized:\n",
    "                if curr_len + 1 <= cohesion_text_len:\n",
    "                    neg_cohesion_train_sents.append(word)\n",
    "                    curr_len += 1\n",
    "                else:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "suited-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_neg_cohesion_train_txt = open(\"neg_cohesion_train_txt.pickle\",\"wb\")\n",
    "pickle.dump(neg_cohesion_train_txt,pickle_neg_cohesion_train_txt)\n",
    "pickle_neg_cohesion_train_txt.close()\n",
    "\n",
    "# neg_cohesion_train_txt = pickle.load(open(\"neg_cohesion_train_txt.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "growing-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_batch_size = 8\n",
    "\n",
    "curr_batch_size = 0\n",
    "for i,story in enumerate(training_stories):\n",
    "    batched_story = [\"\"]\n",
    "    batch_num = 0\n",
    "    for line in story:\n",
    "        if curr_batch_size < line_batch_size:\n",
    "            batched_story[batch_num] += line\n",
    "            curr_batch_size += 1\n",
    "        else:\n",
    "            batched_story.append(line)\n",
    "            batch_num += 1\n",
    "            curr_batch_size = 0\n",
    "    training_stories[i] = batched_story\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interested-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_training_batched_stories = open(\"training_batched_stories.pickle\",\"wb\")\n",
    "pickle.dump(training_stories,pickle_training_batched_stories)\n",
    "pickle_training_batched_stories.close()\n",
    "\n",
    "# training_stories = pickle.load(open(\"batched_training_stories.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "respected-sunglasses",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 0 num batches: 55\n",
      "Story 1 num batches: 75\n",
      "Story 2 num batches: 468\n",
      "Story 3 num batches: 61\n"
     ]
    }
   ],
   "source": [
    "for i,batched_story in enumerate(training_stories):\n",
    "    print(\"Story \" + str(i) + \" num batches: \" + str(len(batched_story)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "handy-moisture",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/4 [00:00<?, ?it/s]\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1517, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|████████████                                                                        | 1/7 [00:29<02:55, 29.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2697, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|████████████████████████                                                            | 2/7 [01:12<03:06, 37.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.9130, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████████████████████████████████████                                                | 3/7 [01:21<01:38, 24.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2903, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|████████████████████████████████████████████████                                    | 4/7 [01:30<00:54, 18.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5014, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [01:39<00:29, 14.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5524, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [01:47<00:12, 12.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1080, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [01:56<00:00, 16.64s/it]\u001b[A\n",
      " 25%|████████████████████▊                                                              | 1/4 [02:03<06:09, 123.24s/it]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3936, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▎                                                                          | 1/10 [00:36<05:31, 36.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4063, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:49<03:00, 22.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6129, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:59<01:56, 16.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1948, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:08<01:21, 13.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8186, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:18<01:01, 12.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0076, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:27<00:44, 11.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8339, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:36<00:31, 10.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8414, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:44<00:19,  9.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7470, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:53<00:09,  9.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5422, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:58<00:00, 11.80s/it]\u001b[A\n",
      " 50%|█████████████████████████████████████████▌                                         | 2/4 [04:10<04:11, 125.66s/it]\n",
      "  0%|                                                                                           | 0/59 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5656, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|█▍                                                                                 | 1/59 [00:12<12:30, 12.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3569, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▊                                                                                | 2/59 [00:22<10:22, 10.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5159, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|████▏                                                                              | 3/59 [00:31<09:15,  9.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1798, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▋                                                                             | 4/59 [00:39<08:41,  9.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0197, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|███████                                                                            | 5/59 [00:49<08:26,  9.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8293, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|████████▍                                                                          | 6/59 [00:58<08:20,  9.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1790, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█████████▊                                                                         | 7/59 [01:07<07:56,  9.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2840, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|███████████▎                                                                       | 8/59 [01:16<07:40,  9.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9582, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|████████████▋                                                                      | 9/59 [01:25<07:33,  9.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3196, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▉                                                                    | 10/59 [01:33<07:16,  8.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3060, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|███████████████▎                                                                  | 11/59 [01:42<07:08,  8.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4543, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|████████████████▋                                                                 | 12/59 [01:51<06:51,  8.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4223, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██████████████████                                                                | 13/59 [01:59<06:38,  8.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1209, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|███████████████████▍                                                              | 14/59 [02:08<06:32,  8.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1693, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|████████████████████▊                                                             | 15/59 [02:17<06:27,  8.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2553, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██████████████████████▏                                                           | 16/59 [02:26<06:16,  8.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1750, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|███████████████████████▋                                                          | 17/59 [02:34<06:05,  8.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0904, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|█████████████████████████                                                         | 18/59 [02:43<06:02,  8.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4691, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|██████████████████████████▍                                                       | 19/59 [02:54<06:11,  9.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3307, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███████████████████████████▊                                                      | 20/59 [03:04<06:19,  9.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1985, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|█████████████████████████████▏                                                    | 21/59 [03:15<06:21, 10.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3596, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|██████████████████████████████▌                                                   | 22/59 [03:25<06:13, 10.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2334, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 39%|███████████████████████████████▉                                                  | 23/59 [03:34<05:52,  9.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9161, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|█████████████████████████████████▎                                                | 24/59 [03:44<05:37,  9.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9677, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|██████████████████████████████████▋                                               | 25/59 [03:53<05:25,  9.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7736, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████████████████████████████████████▏                                             | 26/59 [04:02<05:10,  9.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6413, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|█████████████████████████████████████▌                                            | 27/59 [04:11<04:54,  9.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3650, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|██████████████████████████████████████▉                                           | 28/59 [04:20<04:46,  9.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9202, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 49%|████████████████████████████████████████▎                                         | 29/59 [04:30<04:38,  9.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8724, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████████████████████████████████████████▋                                        | 30/59 [04:39<04:29,  9.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8366, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|███████████████████████████████████████████                                       | 31/59 [04:49<04:26,  9.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2266, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|████████████████████████████████████████████▍                                     | 32/59 [04:58<04:15,  9.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8641, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████████████████████████████████████████████▊                                    | 33/59 [05:08<04:07,  9.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3032, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|███████████████████████████████████████████████▎                                  | 34/59 [05:16<03:50,  9.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2017, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|████████████████████████████████████████████████▋                                 | 35/59 [05:25<03:39,  9.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9788, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 61%|██████████████████████████████████████████████████                                | 36/59 [05:34<03:29,  9.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2756, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|███████████████████████████████████████████████████▍                              | 37/59 [05:43<03:15,  8.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0164, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|████████████████████████████████████████████████████▊                             | 38/59 [05:52<03:09,  9.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9204, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████████████████████████████████████████████████████▏                           | 39/59 [06:01<03:01,  9.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1120, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|███████████████████████████████████████████████████████▌                          | 40/59 [06:10<02:51,  9.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7469, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 69%|████████████████████████████████████████████████████████▉                         | 41/59 [06:21<02:52,  9.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2515, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|██████████████████████████████████████████████████████████▎                       | 42/59 [06:31<02:44,  9.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1121, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████████████████████████████████████████████████████████▊                      | 43/59 [06:41<02:36,  9.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8199, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|█████████████████████████████████████████████████████████████▏                    | 44/59 [06:50<02:23,  9.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1552, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|██████████████████████████████████████████████████████████████▌                   | 45/59 [06:59<02:11,  9.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1169, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████████████████████████████████████████████████████████████▉                  | 46/59 [07:09<02:04,  9.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4599, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|█████████████████████████████████████████████████████████████████▎                | 47/59 [07:17<01:49,  9.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7889, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 81%|██████████████████████████████████████████████████████████████████▋               | 48/59 [07:26<01:40,  9.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9770, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|████████████████████████████████████████████████████████████████████              | 49/59 [07:34<01:27,  8.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0562, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|█████████████████████████████████████████████████████████████████████▍            | 50/59 [07:43<01:19,  8.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1945, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|██████████████████████████████████████████████████████████████████████▉           | 51/59 [07:52<01:09,  8.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7120, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 52/59 [08:01<01:01,  8.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3706, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▋        | 53/59 [08:10<00:53,  8.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0372, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|███████████████████████████████████████████████████████████████████████████       | 54/59 [08:19<00:45,  9.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9116, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▍     | 55/59 [08:29<00:37,  9.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.5831, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████▊    | 56/59 [08:41<00:29,  9.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2889, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▏  | 57/59 [08:51<00:20, 10.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8042, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████▌ | 58/59 [09:00<00:09,  9.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0818, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 59/59 [09:04<00:00,  9.23s/it]\u001b[A\n",
      " 75%|██████████████████████████████████████████████████████████████▎                    | 3/4 [13:25<05:21, 321.83s/it]\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2563, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|██████████▌                                                                         | 1/8 [01:12<08:13, 70.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3347, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|█████████████████████                                                               | 2/8 [01:35<04:22, 43.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3662, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███████████████████████████████▌                                                    | 3/8 [01:45<02:21, 28.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3422, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████████                                          | 4/8 [01:54<01:22, 20.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.3298, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|████████████████████████████████████████████████████▌                               | 5/8 [02:04<00:50, 16.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1923, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████████████████████████████████████████████████████████████                     | 6/8 [02:13<00:28, 14.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5829, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|█████████████████████████████████████████████████████████████████████████▌          | 7/8 [02:23<00:12, 12.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9135, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [02:31<00:00, 18.96s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 4/4 [16:28<00:00, 247.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "for story in tqdm(training_stories[:training_story_count]):\n",
    "    story_dataset = StoryDataset(text=story)\n",
    "    story_loader = DataLoader(story_dataset, batch_size=8)\n",
    "    pickle_trained_model.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "dutch-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_trained_generator = open(\"trained_generator.pickle\",\"wb\")\n",
    "# pickle.dump(story_generator,pickle_trained_generator)\n",
    "# pickle_trained_generator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "meaning-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "simple-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "print(cohesion_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "collectible-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_15 (SimpleRNN)    (None, 64)                53312     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 56,065\n",
      "Trainable params: 56,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embeddings_dim = story_generator.model.transformer.wte.embedding_dim\n",
    "cohesion_model = Sequential()\n",
    "# cohesion_model.add(layers.Embedding(input_dim=embeddings_dim,output_dim=64))\n",
    "cohesion_model.add(layers.SimpleRNN(input_shape=(cohesion_text_len,embeddings_dim),units=64))\n",
    "# cohesion_model.add(layers.SimpleRNN(input_shape=(cohesion_text_len),units=64))\n",
    "cohesion_model.add(layers.Dense(32, activation='relu'))\n",
    "cohesion_model.add(layers.Dense(16, activation='sigmoid'))\n",
    "cohesion_model.add(layers.Dense(8, activation='relu'))\n",
    "cohesion_model.add(layers.Dense(1, activation='softmax'))\n",
    "cohesion_model.summary()\n",
    "cohesion_model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "known-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_x = cohesion_training_text + neg_cohesion_train_txt\n",
    "# train_data_y = cohesion_training_labels + neg_cohesion_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "beneficial-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data_x = []\n",
    "train_data_y = []\n",
    "for i in range(0,100):\n",
    "    rand_sample = random.randint(0,len(cohesion_training_text)-1)\n",
    "    train_data_x.append(cohesion_training_text[rand_sample])\n",
    "    train_data_x.append(neg_cohesion_train_txt[rand_sample])\n",
    "    train_data_y.append(cohesion_training_labels[rand_sample])\n",
    "    train_data_y.append(neg_cohesion_train_labels[rand_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "reflected-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_x))\n",
    "print(len(train_data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "united-street",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.4655 - accuracy: 0.9250\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3928 - accuracy: 0.9600\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3278 - accuracy: 0.9750\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.2754 - accuracy: 0.9850\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2320 - accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1946 - accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1606 - accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.1361 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1196 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1061 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2136a5d2188>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohesion_model.fit(x=train_data_x,y=train_data_y,batch_size=64,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "beginning-programmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cohesion_model\\assets\n"
     ]
    }
   ],
   "source": [
    "cohesion_model.save(\"cohesion_model\")\n",
    "# cohesion_model = tf.keras.models.load_model(\"cohesion_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "sudden-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9153782]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohesion_model.predict([cohesion_training_text[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-reader",
   "metadata": {},
   "source": [
    "# Run all cells in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "effective-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "cohesion_text_len = 112\n",
    "story_generator = pickle.load(open(\"trained_generator.pickle\",\"rb\"))\n",
    "embeddings_dim = embeddings_dim = story_generator.model.transformer.wte.embedding_dim\n",
    "# cohesion_training_stories = pickle.load(open(\"cohesion_training_text.pickle\",\"rb\"))\n",
    "# neg_cohesion_train_txt = pickle.load(open(\"neg_cohesion_train_txt.pickle\",\"rb\"))\n",
    "# training_stories = pickle.load(open(\"batched_training_stories.pickle\",\"rb\"))\n",
    "cohesion_model = tf.keras.models.load_model(\"cohesion_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "complicated-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohesion_value(text,story_generator,cohesion_model,block_len=112):\n",
    "    # text parameter is a string\n",
    "    # This section of code groups the story text into blocks of\n",
    "    # 112 word embeddings (average words per line * 2) \n",
    "    cohesion_blocks = []\n",
    "    text_as_lines = text.splitlines()\n",
    "    \n",
    "    cohesion_usr_sents = []\n",
    "    curr_len = 0\n",
    "    for line in text_as_lines:\n",
    "        if curr_len >= block_len:\n",
    "            cohesion_blocks.append(cohesion_usr_sents)\n",
    "            cohesion_usr_sents = []\n",
    "            curr_len = 0\n",
    "        line_tokenized = get_sent_embedding(line,story_generator)\n",
    "        if len(line_tokenized) + curr_len <= block_len:\n",
    "            cohesion_usr_sents += line_tokenized\n",
    "            curr_len += len(line_tokenized) \n",
    "        else:\n",
    "            for word in line_tokenized:\n",
    "                if curr_len + 1 <= block_len:\n",
    "                    cohesion_usr_sents.append(word)\n",
    "                    curr_len += 1\n",
    "                else:\n",
    "                    break\n",
    "    if len(cohesion_blocks) == 0:\n",
    "        raise RuntimeError(\"block length too small, try using a larger text or lowering block__len\")\n",
    "        \n",
    "    # This section of code uses the cohesion_model (cohesion RNN) to\n",
    "    # classify the text and return the likelyhood that the text is cohesive\n",
    "    raw_predictions = cohesion_model.predict(cohesion_blocks)\n",
    "    return raw_predictions[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-highway",
   "metadata": {},
   "source": [
    "# Don't run cells in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "healthy-mills",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8917127\n"
     ]
    }
   ],
   "source": [
    "test_story = \"I am already far north of London, and as I walk in the streets of \\n\\\n",
    "Petersburgh, I feel a cold northern breeze play upon my cheeks, which \\n \\\n",
    "braces my nerves and fills me with delight. Do you understand this \\n\\\n",
    "feeling?\\n\"\n",
    "\n",
    "print(get_cohesion_value(test_story,story_generator,cohesion_model,block_len=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "double-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9098319\n"
     ]
    }
   ],
   "source": [
    "test_story = \"I far already London dog of north am, I as and the in walk of streets \\n\\\n",
    "Peteear burgh, a el brether cold cat m play which cheeks, \\n \\\n",
    "nervbra wolf m fills and delight with. rstand pig you Do this \\n\\\n",
    "feeling?\\n\"\n",
    "\n",
    "print(get_cohesion_value(test_story,story_generator,cohesion_model,block_len=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-nigeria",
   "metadata": {},
   "source": [
    "# Run these cells to generate and evaluate a story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "systematic-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the first few sentences of your story as a prompt: I am already far north of London, and as I walk in the streets of Petersburgh, I feel a cold northern breeze play upon my cheeks, which braces my nerves and fills me with delight. Do you understand this feeling?\n",
      "Enter the length of your story (number of sentences): 20\n",
      "I am already far north of London, and as I walk in the streets of Petersburgh, I feel a cold northern breeze play upon my cheeks, which braces my nerves and fills me with delight. Do you understand this feeling? It is not just that it was always there; it has been here for years now. The first thing to do was to make sure that she had no other choice but to go on her own way. She did not want to be alone: she wanted to get out of the house by herself. But why should she? Why should she stay at home? And what else could she do? What else would she do? There were three reasons--the one being that she didn't know how to keep up with the new arrivals or who they were going to meet. Her husband's work-life consisted entirely of working himself into oblivion after his wife died. He worked hard, he kept up with him, and he never forgot about them. They are all men, too, so much obliged to their job. Their wives have made us look like children again. We're very young, though we've got our hair back from the old days when we wore skirts and dresses undergarments. In fact, if you ask anyone whose name comes before your eyes, they'll tell you that Mrs. Smith went to New York once every week to see some girl dressed down to an ordinary skirt. That does seem to explain something.\"She laughed. \"Yes, sir, Mr. Biddle,you don't remember anything about those girls?\"Mrs. Smith said quietly.Her voice seemed to say nothing except that she'd heard someone talk about dressing women differently than themselves.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_sent = input(\"Enter the first few sentences of your story as a prompt: \")\n",
    "user_story_len = input(\"Enter the length of your story (number of sentences): \")\n",
    "story_generator.alt_sent_gen_enabled = False\n",
    "story = story_generator.generate_sentences(sent=user_sent,num_sentences=int(user_story_len))\n",
    "print(story)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "experienced-moldova",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88715446\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "story_as_lines = nltk.sent_tokenize(story)\n",
    "story_with_lines = '\\n'.join(story_as_lines)\n",
    "print(get_cohesion_value(text=story_with_lines,story_generator=story_generator,cohesion_model=cohesion_model,block_len=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python A6",
   "language": "python",
   "name": "a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
